# Reduced GPT configuration
# n_layer=4, n_head=4, n_embd=256
# ~12.4M parameters (1/10th of base GPT-2)
batch_size = 8
block_size = 1024
n_layer = 4
n_head = 4
n_embd = 256
dropout = 0.0
bias = True 